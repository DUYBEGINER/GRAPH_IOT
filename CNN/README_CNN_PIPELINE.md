# ğŸ§  PhÃ¡t Hiá»‡n LÆ°u LÆ°á»£ng Máº¡ng IoT Báº¥t ThÆ°á»ng Báº±ng CNN

## Binary Classification: Benign vs Attack
### Dataset: CSE-CIC-IDS2018

---

## ğŸ“ Cáº¥u TrÃºc Project

```
CNN/
â”œâ”€â”€ step1_clean_data.py           # BÆ°á»›c 1: Clean dá»¯ liá»‡u
â”œâ”€â”€ step2_prepare_training_data.py # BÆ°á»›c 2: CÃ¢n báº±ng vÃ  chuáº©n bá»‹ training
â”œâ”€â”€ step3_train_cnn.py            # BÆ°á»›c 3: Train mÃ´ hÃ¬nh CNN
â”œâ”€â”€ cnn_cicids2018_full_pipeline.ipynb  # Notebook cháº¡y trÃªn Kaggle
â”œâ”€â”€ cleaned_data/                 # Dá»¯ liá»‡u Ä‘Ã£ clean (output cá»§a step 1)
â”œâ”€â”€ training_data/                # Dá»¯ liá»‡u training (output cá»§a step 2)
â”œâ”€â”€ models/                       # Model Ä‘Ã£ train (output cá»§a step 3)
â””â”€â”€ logs/                         # TensorBoard logs
```

---

## ğŸš€ HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### Cháº¡y trÃªn Local

```bash
# BÆ°á»›c 1: Clean dá»¯ liá»‡u
python step1_clean_data.py

# BÆ°á»›c 2: CÃ¢n báº±ng vÃ  chuáº©n bá»‹ training
python step2_prepare_training_data.py

# BÆ°á»›c 3: Train mÃ´ hÃ¬nh
python step3_train_cnn.py
```

### Cháº¡y trÃªn Kaggle

1. Upload dataset CSE-CIC-IDS2018 lÃªn Kaggle
2. Táº¡o notebook má»›i
3. Copy ná»™i dung tá»« `cnn_cicids2018_full_pipeline.ipynb`
4. Thay Ä‘á»•i `DATA_DIR` náº¿u cáº§n
5. Cháº¡y tá»«ng cell

---

## ğŸ“Š Chi Tiáº¿t CÃ¡c BÆ°á»›c Xá»­ LÃ½

### BÆ°á»›c 1: Clean Dá»¯ Liá»‡u (`step1_clean_data.py`)

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
1. Äá»c tá»«ng file CSV theo chunks (tá»‘i Æ°u RAM)
2. Loáº¡i bá» cá»™t identification: `Flow ID`, `Src IP`, `Dst IP`, `Src Port`, `Dst Port`, `Timestamp`
3. Loáº¡i bá» cá»™t zero-variance (cá»™t cÃ³ giÃ¡ trá»‹ khÃ´ng Ä‘á»•i)
4. Xá»­ lÃ½ NaN vÃ  Infinity báº±ng **Mode** cá»§a cá»™t
5. Loáº¡i bá» duplicate
6. Chuyá»ƒn nhÃ£n sang binary: Benign=0, Attack=1
7. LÆ°u dá»¯ liá»‡u dáº¡ng `.parquet`

**Output:**
- `cleaned_data/cleaned_data.parquet` - Dá»¯ liá»‡u Ä‘Ã£ clean
- `cleaned_data/feature_names.txt` - TÃªn cÃ¡c features
- `cleaned_data/column_modes.pkl` - Mode cá»§a tá»«ng cá»™t
- `cleaned_data/cleaning_metadata.json` - Thá»‘ng kÃª

### BÆ°á»›c 2: Chuáº©n Bá»‹ Training Data (`step2_prepare_training_data.py`)

**Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh:**
- Tá»•ng máº«u: 3,000,000
- Tá»· lá»‡: 70% Benign, 30% Attack
- Train/Val/Test: 70%/10%/20%

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
1. Äá»c dá»¯ liá»‡u Ä‘Ã£ clean tá»« step 1
2. **CÃ¢n báº±ng dá»¯ liá»‡u** theo tá»· lá»‡ mong muá»‘n (undersample Benign)
3. Ãp dá»¥ng **Log Transform**: `log_e(1+x)`
4. Chuáº©n hÃ³a báº±ng **StandardScaler**
5. Reshape cho CNN: `(samples, features, 1)`
6. Chia train/val/test vá»›i **stratify** Ä‘á»ƒ giá»¯ tá»· lá»‡
7. TÃ­nh **class weights** cho training

**Output:**
- `training_data/X_train.npy`, `X_val.npy`, `X_test.npy`
- `training_data/y_train.npy`, `y_val.npy`, `y_test.npy`
- `training_data/scaler.pkl` - StandardScaler Ä‘Ã£ fit
- `training_data/class_weights.pkl` - Class weights

### BÆ°á»›c 3: Train CNN (`step3_train_cnn.py`)

**Kiáº¿n trÃºc CNN:**
```
Input (n_features, 1)
    â†“
Conv1D (32 filters, kernel=2) â†’ MaxPooling1D (2)
    â†“
Conv1D (32 filters, kernel=2) â†’ MaxPooling1D (2)
    â†“
Conv1D (64 filters, kernel=2) â†’ MaxPooling1D (2)
    â†“
Conv1D (64 filters, kernel=2) â†’ MaxPooling1D (2)
    â†“
Conv1D (64 filters, kernel=2) â†’ MaxPooling1D (2)
    â†“
BatchNormalization â†’ Dropout (0.5)
    â†“
Flatten â†’ Dense (1, sigmoid)
```

**Cáº¥u hÃ¬nh training:**
- Optimizer: Adam (lr=0.001)
- Loss: binary_crossentropy
- Metrics: Accuracy, Precision, Recall
- Batch size: 256
- Epochs: 50 (vá»›i Early Stopping)
- Class weights: CÃ³ (xá»­ lÃ½ imbalance)

**Callbacks:**
- EarlyStopping (patience=10)
- ModelCheckpoint (save best)
- ReduceLROnPlateau (factor=0.5, patience=5)
- TensorBoard

**Output:**
- `models/best_model.keras` - Model tá»‘t nháº¥t
- `models/final_model.keras` - Model cuá»‘i cÃ¹ng
- `models/model_weights.h5` - Weights
- `models/training_history.json` - Lá»‹ch sá»­ training
- `models/evaluation_results.json` - Káº¿t quáº£ Ä‘Ã¡nh giÃ¡
- `models/training_history.png` - Biá»ƒu Ä‘á»“

---

## âš™ï¸ TÃ¹y Chá»‰nh Cáº¥u HÃ¬nh

### Thay Ä‘á»•i tá»· lá»‡ cÃ¢n báº±ng

Trong `step2_prepare_training_data.py`:
```python
TOTAL_SAMPLES = 3000000    # Tá»•ng sá»‘ máº«u
BENIGN_RATIO = 0.70        # 70% Benign
ATTACK_RATIO = 0.30        # 30% Attack
```

### Thay Ä‘á»•i tá»· lá»‡ train/val/test

```python
TEST_SIZE = 0.20   # 20% test
VAL_SIZE = 0.10    # 10% validation
# Train = 70%
```

### Thay Ä‘á»•i hyperparameters

Trong `step3_train_cnn.py`:
```python
BATCH_SIZE = 256
EPOCHS = 50
LEARNING_RATE = 0.001
DROPOUT_RATE = 0.5
PATIENCE = 10
```

---

## ğŸ“‹ YÃªu Cáº§u Há»‡ Thá»‘ng

### Dependencies

```
tensorflow>=2.10.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
tqdm>=4.62.0
pyarrow>=8.0.0  # Cho parquet
```

### CÃ i Ä‘áº·t

```bash
pip install tensorflow numpy pandas scikit-learn matplotlib tqdm pyarrow
```

### RAM khuyáº¿n nghá»‹
- Clean data: 16GB+
- Training: 8GB+ (vá»›i batch_size=256)

### GPU (optional)
- NVIDIA GPU vá»›i CUDA support sáº½ tÄƒng tá»‘c training Ä‘Ã¡ng ká»ƒ

---

## ğŸ“Š Káº¿t Quáº£ Mong Äá»£i

Vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh (3M máº«u, 70-30 split):

| Metric | GiÃ¡ trá»‹ ká»³ vá»ng |
|--------|-----------------|
| Accuracy | 95-98% |
| Precision | 90-95% |
| Recall | 85-95% |
| F1-Score | 88-95% |

---

## ğŸ”§ Troubleshooting

### Lá»—i: "Object of type int64 is not JSON serializable"
- ÄÃ£ Ä‘Æ°á»£c fix trong code báº±ng cÃ¡ch chuyá»ƒn numpy types sang Python native

### Lá»—i: Out of Memory
- Giáº£m `CHUNK_SIZE` trong step 1 vÃ  2
- Giáº£m `BATCH_SIZE` trong step 3
- Giáº£m `TOTAL_SAMPLES`

### Lá»—i: KhÃ´ng tÃ¬m tháº¥y file CSV
- Kiá»ƒm tra `DATA_DIR` Ä‘Ãºng Ä‘Æ°á»ng dáº«n
- Äáº£m báº£o file CSV cÃ³ pattern `*_TrafficForML_CICFlowMeter.csv`

---

## ğŸ“ Ghi ChÃº

1. **Táº¡i sao cÃ¢n báº±ng 70-30 thay vÃ¬ 50-50?**
   - Dá»¯ liá»‡u thá»±c táº¿ thÆ°á»ng cÃ³ nhiá»u traffic bÃ¬nh thÆ°á»ng hÆ¡n
   - 70-30 váº«n giá»¯ Ä‘Æ°á»£c Ä‘áº·c tÃ­nh thá»±c táº¿ nhÆ°ng giáº£m imbalance

2. **Táº¡i sao dÃ¹ng Log Transform?**
   - Network flow data thÆ°á»ng cÃ³ phÃ¢n phá»‘i lá»‡ch (skewed)
   - Log transform giÃºp giáº£m skewness vÃ  cáº£i thiá»‡n model

3. **Táº¡i sao dÃ¹ng Mode thay vÃ¬ Mean/Median cho NaN?**
   - Theo yÃªu cáº§u cá»§a bÃ i toÃ¡n
   - Mode giá»¯ Ä‘Æ°á»£c giÃ¡ trá»‹ phá»• biáº¿n nháº¥t cá»§a feature

4. **Class Weights hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?**
   - TÄƒng weight cho class thiá»ƒu sá»‘ (Attack)
   - GiÃºp model khÃ´ng bá»‹ bias vá» class Ä‘a sá»‘

