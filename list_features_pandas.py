"""
Script li·ªát k√™ c√°c ƒë·∫∑c tr∆∞ng (features/columns) trong t·ª´ng file dataset CICIDS2018
S·ª≠ d·ª•ng pandas ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt
"""

import pandas as pd
import os
from pathlib import Path

# ================== C·∫§U H√åNH ==================
DATA_DIR = r"D:\PROJECT\Machine Learning\IOT\CICIDS2018-CSV"
OUTPUT_FILE = "features_summary.txt"

def analyze_csv_features(csv_file):
    """
    Ph√¢n t√≠ch chi ti·∫øt c√°c features c·ªßa m·ªôt file CSV

    Args:
        csv_file: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV

    Returns:
        dict: Th√¥ng tin v·ªÅ c√°c features
    """
    try:
        # ƒê·ªçc file CSV v·ªõi low_memory=False ƒë·ªÉ tr√°nh warning
        df = pd.read_csv(csv_file, low_memory=False)

        # L·∫•y th√¥ng tin c∆° b·∫£n
        info = {
            'filename': csv_file.name,
            'num_rows': len(df),
            'num_columns': len(df.columns),
            'columns': df.columns.tolist(),
            'dtypes': df.dtypes.to_dict(),
            'missing_values': df.isnull().sum().to_dict(),
            'memory_usage': df.memory_usage(deep=True).sum() / (1024 ** 2)  # MB
        }

        return info, df

    except Exception as e:
        return {'error': str(e), 'filename': csv_file.name}, None


def list_features_in_datasets(data_dir, output_file):
    """
    Li·ªát k√™ v√† ph√¢n t√≠ch t·∫•t c·∫£ c√°c features trong dataset CICIDS2018

    Args:
        data_dir: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c file CSV
        output_file: T√™n file ƒë·ªÉ l∆∞u k·∫øt qu·∫£
    """
    print("=" * 100)
    print("SCRIPT LI·ªÜT K√ä C√ÅC ƒê·∫∂C TR∆ØNG TRONG DATASET CICIDS2018 (PANDAS VERSION)")
    print("=" * 100)

    # T√¨m t·∫•t c·∫£ c√°c file CSV
    csv_files = sorted(Path(data_dir).glob("*_TrafficForML_CICFlowMeter.csv"))

    if not csv_files:
        print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file CSV n√†o trong th∆∞ m·ª•c: {data_dir}")
        return

    print(f"\nüìÅ Th∆∞ m·ª•c d·ªØ li·ªáu: {data_dir}")
    print(f"üìä T√¨m th·∫•y {len(csv_files)} file CSV\n")

    # L∆∞u th√¥ng tin t·∫•t c·∫£ c√°c file
    all_features_info = {}
    all_features_set = set()
    all_dtypes = {}

    # M·ªü file output
    output_path = os.path.join(data_dir, output_file)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 100 + "\n")
        f.write("DANH S√ÅCH C√ÅC ƒê·∫∂C TR∆ØNG (FEATURES) TRONG DATASET CICIDS2018\n")
        f.write("Ph√¢n t√≠ch chi ti·∫øt v·ªõi pandas\n")
        f.write("=" * 100 + "\n\n")

        # Ph√¢n t√≠ch t·ª´ng file
        for idx, csv_file in enumerate(csv_files, 1):
            filename = csv_file.name
            print(f"[{idx}/{len(csv_files)}] ƒêang x·ª≠ l√Ω: {filename}")

            info, df = analyze_csv_features(csv_file)

            if 'error' in info:
                print(f"    ‚úó L·ªói: {info['error']}")
                f.write(f"\nFile: {filename}\n")
                f.write(f"L·ªñI: {info['error']}\n")
                continue

            # L∆∞u th√¥ng tin
            all_features_info[filename] = info
            all_features_set.update(info['columns'])

            # L∆∞u dtype c·ªßa m·ªói feature
            for col, dtype in info['dtypes'].items():
                if col not in all_dtypes:
                    all_dtypes[col] = {}
                all_dtypes[col][filename] = str(dtype)

            # Ghi v√†o file output
            f.write(f"\n{'=' * 100}\n")
            f.write(f"File: {filename}\n")
            f.write(f"{'=' * 100}\n")
            f.write(f"S·ªë d√≤ng:        {info['num_rows']:,}\n")
            f.write(f"S·ªë c·ªôt:         {info['num_columns']}\n")
            f.write(f"Dung l∆∞·ª£ng RAM: {info['memory_usage']:.2f} MB\n")
            f.write(f"\n{'-' * 100}\n")
            f.write(f"{'STT':<5} {'T√äN C·ªòT':<50} {'KI·ªÇU D·ªÆ LI·ªÜU':<20} {'MISSING VALUES':<15}\n")
            f.write(f"{'-' * 100}\n")

            for i, col in enumerate(info['columns'], 1):
                dtype = str(info['dtypes'][col])
                missing = info['missing_values'][col]
                f.write(f"{i:<5} {col:<50} {dtype:<20} {missing:<15}\n")

            # In ra m√†n h√¨nh
            print(f"    ‚úì S·ªë d√≤ng: {info['num_rows']:,}")
            print(f"    ‚úì S·ªë c·ªôt: {info['num_columns']}")
            print(f"    ‚úì RAM: {info['memory_usage']:.2f} MB")

            # Ki·ªÉm tra c√°c c·ªôt c√≥ missing values
            missing_cols = [col for col, count in info['missing_values'].items() if count > 0]
            if missing_cols:
                print(f"    ‚ö†Ô∏è  {len(missing_cols)} c·ªôt c√≥ missing values")

        # ============== T√ìM T·∫ÆT T·ªîNG QUAN ==============
        print("\n" + "=" * 100)
        print("T√ìM T·∫ÆT T·ªîNG QUAN")
        print("=" * 100)

        f.write(f"\n\n{'=' * 100}\n")
        f.write("T√ìM T·∫ÆT T·ªîNG QUAN\n")
        f.write(f"{'=' * 100}\n\n")

        # Th·ªëng k√™ c∆° b·∫£n
        total_files = len(all_features_info)
        total_features = len(all_features_set)
        total_rows = sum(info['num_rows'] for info in all_features_info.values() if 'num_rows' in info)
        total_memory = sum(info['memory_usage'] for info in all_features_info.values() if 'memory_usage' in info)

        summary_stats = [
            f"T·ªïng s·ªë file:              {total_files}",
            f"T·ªïng s·ªë features duy nh·∫•t: {total_features}",
            f"T·ªïng s·ªë d√≤ng d·ªØ li·ªáu:      {total_rows:,}",
            f"T·ªïng dung l∆∞·ª£ng RAM:       {total_memory:.2f} MB",
        ]

        for stat in summary_stats:
            print(stat)
            f.write(stat + "\n")

        # Ki·ªÉm tra schema consistency
        print("\n" + "-" * 100)
        f.write("\n" + "-" * 100 + "\n")

        if all_features_info:
            first_file = list(all_features_info.keys())[0]
            first_columns = set(all_features_info[first_file]['columns'])
            all_same = True

            for filename, info in all_features_info.items():
                if set(info['columns']) != first_columns:
                    all_same = False
                    break

            if all_same:
                msg = "‚úì T·∫•t c·∫£ c√°c file c√≥ c√πng schema (c√°c c·ªôt gi·ªëng nhau v√† c√πng th·ª© t·ª±)"
                print(msg)
                f.write(msg + "\n")
            else:
                msg = "‚ö†Ô∏è  C√°c file c√≥ schema kh√°c nhau"
                print(msg)
                f.write(msg + "\n\n")
                f.write("CHI TI·∫æT S·ª∞ KH√ÅC BI·ªÜT:\n")
                f.write("-" * 100 + "\n")

                for filename, info in all_features_info.items():
                    file_columns = set(info['columns'])
                    missing = first_columns - file_columns
                    extra = file_columns - first_columns

                    if missing or extra:
                        f.write(f"\nFile: {filename}\n")
                        if missing:
                            f.write(f"  Thi·∫øu c·ªôt: {sorted(missing)}\n")
                        if extra:
                            f.write(f"  C·ªôt th√™m: {sorted(extra)}\n")

        # ============== DANH S√ÅCH T·∫§T C·∫¢ FEATURES ==============
        f.write(f"\n\n{'=' * 100}\n")
        f.write("DANH S√ÅCH T·∫§T C·∫¢ C√ÅC FEATURES DUY NH·∫§T\n")
        f.write(f"{'=' * 100}\n\n")
        f.write(f"{'STT':<5} {'T√äN FEATURE':<60} {'KI·ªÇU D·ªÆ LI·ªÜU PH·ªî BI·∫æN':<30}\n")
        f.write("-" * 100 + "\n")

        for i, feature in enumerate(sorted(all_features_set), 1):
            # X√°c ƒë·ªãnh ki·ªÉu d·ªØ li·ªáu ph·ªï bi·∫øn nh·∫•t cho feature n√†y
            if feature in all_dtypes:
                dtype_counts = {}
                for dtype in all_dtypes[feature].values():
                    dtype_counts[dtype] = dtype_counts.get(dtype, 0) + 1
                most_common_dtype = max(dtype_counts, key=dtype_counts.get)
            else:
                most_common_dtype = "Unknown"

            f.write(f"{i:<5} {feature:<60} {most_common_dtype:<30}\n")

        # ============== PH√ÇN T√çCH KI·ªÇU D·ªÆ LI·ªÜU ==============
        f.write(f"\n\n{'=' * 100}\n")
        f.write("PH√ÇN T√çCH KI·ªÇU D·ªÆ LI·ªÜU C·ª¶A C√ÅC FEATURES\n")
        f.write(f"{'=' * 100}\n\n")

        # ƒê·∫øm c√°c lo·∫°i dtype
        dtype_summary = {}
        for feature, dtypes_dict in all_dtypes.items():
            for dtype in dtypes_dict.values():
                # Chu·∫©n h√≥a dtype name
                if 'int' in dtype:
                    dtype_category = 'Integer'
                elif 'float' in dtype:
                    dtype_category = 'Float'
                elif 'object' in dtype:
                    dtype_category = 'Object/String'
                else:
                    dtype_category = dtype

                dtype_summary[dtype_category] = dtype_summary.get(dtype_category, 0) + 1

        f.write("Ph√¢n b·ªë ki·ªÉu d·ªØ li·ªáu:\n")
        f.write("-" * 100 + "\n")
        for dtype, count in sorted(dtype_summary.items(), key=lambda x: x[1], reverse=True):
            f.write(f"  {dtype:<30} {count:>5} features\n")

    print(f"\n‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {output_path}")
    print("=" * 100)

    # Hi·ªÉn th·ªã preview c√°c features
    if all_features_set:
        print("\nüìã DANH S√ÅCH 20 FEATURES ƒê·∫¶U TI√äN:")
        print("-" * 100)
        for i, feature in enumerate(sorted(all_features_set)[:20], 1):
            # L·∫•y dtype ph·ªï bi·∫øn
            if feature in all_dtypes:
                dtype_counts = {}
                for dtype in all_dtypes[feature].values():
                    dtype_counts[dtype] = dtype_counts.get(dtype, 0) + 1
                most_common_dtype = max(dtype_counts, key=dtype_counts.get)
            else:
                most_common_dtype = "Unknown"

            print(f"  {i:2d}. {feature:<50} [{most_common_dtype}]")

        if len(all_features_set) > 20:
            print(f"\n  ... v√† {len(all_features_set) - 20} features kh√°c")

        print("\nüìä PH√ÇN B·ªê KI·ªÇU D·ªÆ LI·ªÜU:")
        print("-" * 100)
        for dtype, count in sorted(dtype_summary.items(), key=lambda x: x[1], reverse=True):
            print(f"  {dtype:<30} {count:>5} features")

    return all_features_info, all_features_set


def main():
    """H√†m main ƒë·ªÉ ch·∫°y script"""
    print("\nüöÄ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch dataset CICIDS2018...\n")

    features_info, all_features = list_features_in_datasets(DATA_DIR, OUTPUT_FILE)

    if features_info:
        print("\n" + "=" * 100)
        print("CHI TI·∫æT S·ªê L∆Ø·ª¢NG D√íNG V√Ä C·ªòT TRONG T·ª™NG FILE")
        print("=" * 100)
        print(f"{'FILE NAME':<60} {'D√íNG':>15} {'C·ªòT':>10} {'RAM (MB)':>12}")
        print("-" * 100)

        for filename, info in features_info.items():
            if 'num_rows' in info:
                print(f"{filename:<60} {info['num_rows']:>15,} {info['num_columns']:>10} {info['memory_usage']:>12.2f}")

        print("=" * 100)

    print("\n‚úÖ Ho√†n th√†nh! Ki·ªÉm tra file features_summary.txt ƒë·ªÉ xem chi ti·∫øt ƒë·∫ßy ƒë·ªß.")


if __name__ == "__main__":
    main()

