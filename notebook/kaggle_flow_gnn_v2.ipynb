{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6313c1d7",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Install Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13765e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch torch-geometric faiss-cpu scikit-learn pandas numpy tqdm matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6e35d",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Upload Data Files\n",
    "Upload c√°c file sau l√™n Kaggle (t·ª´ dataset-processed/):\n",
    "- `X.npy` - Features (~3M samples, ƒë√£ ƒë∆∞·ª£c scaled)\n",
    "- `y.npy` - Labels  \n",
    "- `idx_train.npy` - Training indices\n",
    "- `idx_val.npy` - Validation indices\n",
    "- `idx_test.npy` - Test indices\n",
    "\n",
    "**L∆∞u √Ω**: Dataset n√†y ƒë∆∞·ª£c build t·ª´ to√†n b·ªô 10 file CSV CICIDS2018 (~3 tri·ªáu flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc05a8",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Utils Functions (utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for flow_gnn package.\"\"\"\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, roc_curve, auc, classification_report\n",
    ")\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "\n",
    "def get_device(device_str: str = \"auto\") -> torch.device:\n",
    "    \"\"\"Get PyTorch device.\"\"\"\n",
    "    if device_str == \"auto\":\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(device_str)\n",
    "    \n",
    "    return device\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, \n",
    "                    y_probs: Optional[np.ndarray] = None) -> Dict[str, float]:\n",
    "    \"\"\"Compute comprehensive metrics.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        y_probs: Predicted probabilities (optional, for AUC)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    # FAR (False Alarm Rate) and Detection Rate\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    metrics[\"far\"] = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    metrics[\"detection_rate\"] = metrics[\"recall\"]\n",
    "    \n",
    "    # AUC if probabilities provided\n",
    "    if y_probs is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "        metrics[\"auc\"] = auc(fpr, tpr)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_metrics_plots(y_true: np.ndarray, y_pred: np.ndarray, \n",
    "                       y_probs: np.ndarray, metrics: Dict[str, float],\n",
    "                       output_dir: str, history: Optional[Dict] = None):\n",
    "    \"\"\"Save comprehensive performance visualization plots.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        y_probs: Predicted probabilities\n",
    "        metrics: Computed metrics dictionary\n",
    "        output_dir: Directory to save plots\n",
    "        history: Training history (optional)\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Benign', 'Attack'],\n",
    "                yticklabels=['Benign', 'Attack'], ax=ax)\n",
    "    ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('True Label', fontsize=12)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. ROC Curve\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "            label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "    ax.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc=\"lower right\", fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path / 'roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Metrics Bar Chart\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
    "    metric_values = [\n",
    "        metrics.get('accuracy', 0),\n",
    "        metrics.get('precision', 0),\n",
    "        metrics.get('recall', 0),\n",
    "        metrics.get('f1', 0),\n",
    "        metrics.get('auc', 0)\n",
    "    ]\n",
    "    \n",
    "    bars = ax.bar(metric_names, metric_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title('Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path / 'metrics_bar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Training History (if provided)\n",
    "    if history is not None:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        if 'train_loss' in history and 'val_loss' in history:\n",
    "            axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "            axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "            axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[0].set_ylabel('Loss', fontsize=12)\n",
    "            axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "            axes[0].legend(fontsize=10)\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # F1 plot\n",
    "        if 'val_f1' in history:\n",
    "            axes[1].plot(history['val_f1'], label='Val F1', color='green', linewidth=2)\n",
    "            axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[1].set_ylabel('F1 Score', fontsize=12)\n",
    "            axes[1].set_title('Validation F1 Score', fontsize=14, fontweight='bold')\n",
    "            axes[1].legend(fontsize=10)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"üìä Plots saved to {output_path}/\")\n",
    "\n",
    "\n",
    "def save_metrics_report(metrics: Dict[str, float], output_dir: str, \n",
    "                        y_true: np.ndarray = None, y_pred: np.ndarray = None,\n",
    "                        latency: Optional[float] = None):\n",
    "    \"\"\"Save metrics to JSON and CSV files.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Metrics dictionary\n",
    "        output_dir: Directory to save reports\n",
    "        y_true: True labels (for classification report)\n",
    "        y_pred: Predicted labels (for classification report)\n",
    "        latency: Inference latency in seconds (optional)\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Add latency if provided\n",
    "    if latency is not None:\n",
    "        metrics['latency_seconds'] = latency\n",
    "        metrics['latency_ms'] = latency * 1000\n",
    "    \n",
    "    # Save as JSON\n",
    "    with open(output_path / 'metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    # Save as CSV\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_path / 'metrics.csv', index=False)\n",
    "    \n",
    "    # Save classification report if labels provided\n",
    "    if y_true is not None and y_pred is not None:\n",
    "        report = classification_report(y_true, y_pred, \n",
    "                                       target_names=['Benign', 'Attack'],\n",
    "                                       digits=4)\n",
    "        with open(output_path / 'classification_report.txt', 'w') as f:\n",
    "            f.write(\"Classification Report\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(report)\n",
    "            f.write(\"\\n\\nDetailed Metrics\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            for key, value in metrics.items():\n",
    "                f.write(f\"{key:20s}: {value:.6f}\\n\")\n",
    "    \n",
    "    print(f\"üìÑ Metrics saved to {output_path}/\")\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping callback.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int = 10, min_delta: float = 1e-4):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "    \n",
    "    def __call__(self, score: float) -> bool:\n",
    "        \"\"\"Check if should stop.\"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return False\n",
    "        \n",
    "        if score > self.best_score + self.min_delta:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "print(\"‚úÖ Utils functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c85b26",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Graph Builder (graph.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build KNN graph from features using FAISS for efficient ANN.\"\"\"\n",
    "\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_knn_graph(X_scaled: np.ndarray, k: int = 10) -> torch.Tensor:\n",
    "    \"\"\"Build KNN graph with progress tracking.\"\"\"\n",
    "    \n",
    "    print(f\"üî® Building KNN graph (k={k})...\")\n",
    "    \n",
    "    # Prepare data for FAISS\n",
    "    X = np.ascontiguousarray(X_scaled, dtype=np.float32)\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    print(f\"   Data shape: {n_samples:,} samples √ó {n_features} features\")\n",
    "    \n",
    "    # Normalize vectors\n",
    "    with tqdm(total=1, desc=\"Normalizing vectors\", ncols=100) as pbar:\n",
    "        faiss.normalize_L2(X)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    with tqdm(total=1, desc=\"Building FAISS index\", ncols=100) as pbar:\n",
    "        index = faiss.IndexFlatIP(n_features)\n",
    "        index.add(X)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Search for k+1 neighbors (including self)\n",
    "    print(f\"   Searching for {k} nearest neighbors...\")\n",
    "    with tqdm(total=n_samples, desc=\"KNN search\", unit=\"samples\", ncols=100) as pbar:\n",
    "        batch_size = 10000\n",
    "        all_indices = []\n",
    "        \n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, n_samples)\n",
    "            _, indices = index.search(X[i:end_idx], k + 1)\n",
    "            all_indices.append(indices)\n",
    "            pbar.update(end_idx - i)\n",
    "        \n",
    "        indices = np.vstack(all_indices)\n",
    "    \n",
    "    # Remove self-loops\n",
    "    indices = indices[:, 1:]\n",
    "    \n",
    "    # Build edge list\n",
    "    with tqdm(total=1, desc=\"Building edges\", ncols=100) as pbar:\n",
    "        row = np.repeat(np.arange(n_samples), k)\n",
    "        col = indices.flatten()\n",
    "        \n",
    "        # Symmetrize\n",
    "        edges = np.vstack([\n",
    "            np.concatenate([row, col]),\n",
    "            np.concatenate([col, row])\n",
    "        ])\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    with tqdm(total=1, desc=\"Removing duplicates\", ncols=100) as pbar:\n",
    "        edges = np.unique(edges, axis=1)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "    \n",
    "    num_edges = edge_index.shape[1]\n",
    "    avg_degree = num_edges / n_samples\n",
    "    \n",
    "    print(f\"‚úÖ KNN graph built: {num_edges:,} edges, avg degree: {avg_degree:.2f}\")\n",
    "    \n",
    "    return edge_index\n",
    "\n",
    "print(\"‚úÖ Graph builder loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2245c",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Model Definition (model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GraphSAGE model for flow classification.\"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class FlowGraphSAGE(torch.nn.Module):\n",
    "    \"\"\"GraphSAGE model for flow classification.\"\"\"    \n",
    "    def __init__(self, in_dim: int, hidden_dim: int = 128, num_classes: int = 2, num_layers: int = 2, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Build GraphSAGE layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_dim, hidden_dim))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        if num_layers > 1:\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # Classifier - output 1 logit for binary classification\n",
    "        self.classifier = torch.nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        print(f\"‚úÖ FlowGraphSAGE: {in_dim}‚Üí{hidden_dim}x{num_layers}‚Üí1 (binary)\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass. Returns logits (no sigmoid).\"\"\"\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.classifier(x)  # Shape: [N, 1]\n",
    "        return x.squeeze(-1)  # Shape: [N]\n",
    "    \n",
    "    def get_embeddings(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get node embeddings before classification.\"\"\"\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "print(\"‚úÖ Model definition loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b43061",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Training Functions (train.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6accb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training functions for Flow-based GNN.\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "class RandomNodeSampler:\n",
    "    \"\"\"Simple random node sampler for mini-batch training on full graph.\n",
    "    \n",
    "    Instead of sampling neighbors (which requires pyg-lib/torch-sparse),\n",
    "    we sample random nodes and compute loss only on those nodes while\n",
    "    using the full graph for message passing.\n",
    "    \"\"\"\n",
    "    def __init__(self, mask: torch.Tensor, batch_size: int, shuffle: bool = True):\n",
    "        self.node_indices = mask.nonzero(as_tuple=True)[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = self.node_indices.clone()\n",
    "        if self.shuffle:\n",
    "            perm = torch.randperm(len(indices))\n",
    "            indices = indices[perm]\n",
    "        \n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            yield indices[i:i + self.batch_size]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.node_indices) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "\n",
    "def train_flow_gnn(\n",
    "    x_tensor: torch.Tensor,\n",
    "    y_tensor: torch.Tensor,\n",
    "    edge_index: torch.Tensor,\n",
    "    train_mask: torch.Tensor,\n",
    "    val_mask: torch.Tensor,\n",
    "    test_mask: torch.Tensor,\n",
    "    config: dict,\n",
    "    device: torch.device\n",
    ") -> Dict:\n",
    "    \"\"\"Train Flow-based GNN model with comprehensive logging and progress tracking.\n",
    "    \n",
    "    Uses full-graph message passing with mini-batch node sampling for loss computation.\n",
    "    This approach doesn't require pyg-lib or torch-sparse.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ TRAINING FLOW-BASED GNN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create PyG Data and move to device\n",
    "    data = Data(\n",
    "        x=x_tensor,\n",
    "        edge_index=edge_index,\n",
    "        y=y_tensor,\n",
    "        train_mask=train_mask,\n",
    "        val_mask=val_mask,\n",
    "        test_mask=test_mask\n",
    "    ).to(device)\n",
    "    \n",
    "    # Calculate pos_weight from TRAINING set only\n",
    "    y_train = y_tensor[train_mask]\n",
    "    pos = (y_train == 1).sum().item()\n",
    "    neg = (y_train == 0).sum().item()\n",
    "    pos_weight = neg / pos if pos > 0 else 1.0\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Training samples: {train_mask.sum().item():,}\")\n",
    "    print(f\"   Validation samples: {val_mask.sum().item():,}\")\n",
    "    print(f\"   Test samples: {test_mask.sum().item():,}\")\n",
    "    print(f\"   Class distribution (train): Benign={neg:,} ({neg/(neg+pos)*100:.1f}%), Attack={pos:,} ({pos/(neg+pos)*100:.1f}%)\")\n",
    "    print(f\"   Positive weight (for loss): {pos_weight:.4f}\")\n",
    "    \n",
    "    # Model\n",
    "    print(f\"\\nüèóÔ∏è  Building Model:\")\n",
    "    model = FlowGraphSAGE(\n",
    "        in_dim=x_tensor.shape[1],\n",
    "        hidden_dim=config['model']['hidden_dim'],\n",
    "        num_classes=config['model']['num_classes'],\n",
    "        num_layers=config['model']['num_layers'],\n",
    "        dropout=config['model']['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    \n",
    "    # Optimizer & Loss (BCEWithLogitsLoss with pos_weight)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config['training']['learning_rate'],\n",
    "        weight_decay=config['training'].get('weight_decay', 0)\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss(\n",
    "        pos_weight=torch.tensor([pos_weight], device=device)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è  Training Configuration:\")\n",
    "    print(f\"   Epochs: {config['training']['epochs']}\")\n",
    "    print(f\"   Batch size: {config['training']['batch_size']}\")\n",
    "    print(f\"   Learning rate: {config['training']['learning_rate']}\")\n",
    "    print(f\"   Weight decay: {config['training'].get('weight_decay', 0)}\")\n",
    "    print(f\"   Early stopping patience: {config['training'].get('patience', 10)}\")\n",
    "    print(f\"   Mode: Full-graph message passing with mini-batch loss\")\n",
    "    \n",
    "    # Random node sampler for training\n",
    "    train_sampler = RandomNodeSampler(\n",
    "        train_mask,\n",
    "        batch_size=config['training']['batch_size'],\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Training loop with history tracking\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=config['training'].get('patience', 10),\n",
    "        min_delta=config['training'].get('min_delta', 0.001)\n",
    "    )\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_f1': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüî• Starting Training...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Progress bar for epochs\n",
    "    epoch_pbar = tqdm(range(1, config['training']['epochs'] + 1), \n",
    "                      desc=\"Training\", unit=\"epoch\", ncols=120)\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        # Train - full graph forward pass, mini-batch loss\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_nodes in train_sampler:\n",
    "            batch_nodes = batch_nodes.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Full graph forward pass\n",
    "            logits = model(data.x, data.edge_index)\n",
    "            \n",
    "            # Compute loss only on batch nodes\n",
    "            loss = criterion(logits[batch_nodes], data.y[batch_nodes].float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        train_loss = total_loss / num_batches\n",
    "        \n",
    "        # Validate - full graph inference\n",
    "        val_loss, val_metrics = evaluate(model, data, val_mask, criterion, device)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_f1'].append(val_metrics['f1'])\n",
    "        history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "        \n",
    "        # Update progress bar\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train_loss': f\"{train_loss:.4f}\",\n",
    "            'val_loss': f\"{val_loss:.4f}\",\n",
    "            'val_f1': f\"{val_metrics['f1']:.4f}\",\n",
    "            'val_acc': f\"{val_metrics['accuracy']:.4f}\"\n",
    "        })\n",
    "        \n",
    "        # Log important epochs\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(\n",
    "                f\"   Epoch {epoch:3d}/{config['training']['epochs']} | \"\n",
    "                f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "                f\"Val F1: {val_metrics['f1']:.4f} | Val Acc: {val_metrics['accuracy']:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics['f1'] > best_f1:\n",
    "            best_f1 = val_metrics['f1']\n",
    "            save_path = Path(config.get('output_dir', 'output/flow_gnn')) / 'best_model.pt'\n",
    "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'metrics': val_metrics,\n",
    "                'config': config\n",
    "            }, save_path)\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopping(val_metrics['f1']):\n",
    "            print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    epoch_pbar.close()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"   Best validation F1: {best_f1:.4f}\")\n",
    "    \n",
    "    # Tune threshold on validation set\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ TUNING DECISION THRESHOLD\")\n",
    "    print(\"=\"*80)\n",
    "    best_threshold = tune_threshold(model, data, val_mask, device)\n",
    "    print(f\"‚úÖ Optimal threshold: {best_threshold:.4f}\")\n",
    "    \n",
    "    # Test with tuned threshold\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üß™ FINAL EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    test_loss, test_metrics, y_true, y_pred, y_probs = evaluate_with_predictions(\n",
    "        model, data, test_mask, criterion, best_threshold, device\n",
    "    )\n",
    "    inference_time = time.time() - start_time\n",
    "    latency_per_sample = inference_time / len(y_true)\n",
    "    \n",
    "    print(f\"\\nüìà Test Results:\")\n",
    "    print(f\"   Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"   Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {test_metrics['recall']:.4f}\")\n",
    "    print(f\"   F1 Score:  {test_metrics['f1']:.4f}\")\n",
    "    if 'auc' in test_metrics:\n",
    "        print(f\"   AUC:       {test_metrics['auc']:.4f}\")\n",
    "    print(f\"   FAR:       {test_metrics['far']:.4f}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Inference Performance:\")\n",
    "    print(f\"   Total time: {inference_time:.2f}s\")\n",
    "    print(f\"   Latency per sample: {latency_per_sample*1000:.4f}ms\")\n",
    "    print(f\"   Throughput: {len(y_true)/inference_time:.2f} samples/sec\")\n",
    "    \n",
    "    # Save visualizations and reports\n",
    "    output_dir = Path(config.get('output_dir', 'output/flow_gnn'))\n",
    "    print(f\"\\nüíæ Saving results to {output_dir}/\")\n",
    "    \n",
    "    save_metrics_plots(y_true, y_pred, y_probs, test_metrics, \n",
    "                      str(output_dir), history=history)\n",
    "    save_metrics_report(test_metrics, str(output_dir), \n",
    "                       y_true, y_pred, latency=latency_per_sample)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nüìä Detailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Benign', 'Attack'], digits=4))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ú® ALL DONE!\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return test_metrics\n",
    "\n",
    "\n",
    "def tune_threshold(model, data, mask, device):\n",
    "    \"\"\"Find optimal threshold on validation set to maximize F1 score.\n",
    "    \n",
    "    Uses full-graph inference (no neighbor sampling).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        val_logits = logits[mask]\n",
    "        val_targets = data.y[mask]\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "    y_val_np = val_targets.cpu().numpy()\n",
    "    \n",
    "    # Search for best threshold with progress bar\n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    best_precision, best_recall = 0.0, 0.0\n",
    "    \n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    for t in tqdm(thresholds, desc=\"Searching threshold\", ncols=100, leave=False):\n",
    "        y_pred = (val_probs >= t).astype(int)\n",
    "        f1 = f1_score(y_val_np, y_pred, zero_division=0)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "            best_precision = precision_score(y_val_np, y_pred, zero_division=0)\n",
    "            best_recall = recall_score(y_val_np, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"   Threshold: {best_t:.4f}\")\n",
    "    print(f\"   Precision: {best_precision:.4f}\")\n",
    "    print(f\"   Recall:    {best_recall:.4f}\")\n",
    "    print(f\"   F1 Score:  {best_f1:.4f}\")\n",
    "    \n",
    "    return best_t\n",
    "\n",
    "\n",
    "def evaluate(model, data, mask, criterion, device, threshold=0.5):\n",
    "    \"\"\"Evaluate model on given mask using full-graph inference.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        \n",
    "        # Get predictions for masked nodes\n",
    "        mask_logits = logits[mask]\n",
    "        mask_y = data.y[mask]\n",
    "        \n",
    "        loss = criterion(mask_logits, mask_y.float()).item()\n",
    "    \n",
    "    # Convert logits to probabilities and apply threshold\n",
    "    probs = torch.sigmoid(mask_logits).cpu().numpy()\n",
    "    pred = (probs >= threshold).astype(int)\n",
    "    true = mask_y.cpu().numpy()\n",
    "    \n",
    "    metrics = compute_metrics(true, pred, y_probs=probs)\n",
    "    \n",
    "    return loss, metrics\n",
    "\n",
    "\n",
    "def evaluate_with_predictions(model, data, mask, criterion, threshold, device):\n",
    "    \"\"\"Evaluate and return predictions using full-graph inference.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        \n",
    "        # Get predictions for masked nodes\n",
    "        mask_logits = logits[mask]\n",
    "        mask_y = data.y[mask]\n",
    "        \n",
    "        loss = criterion(mask_logits, mask_y.float()).item()\n",
    "    \n",
    "    # Convert logits to probabilities and apply threshold\n",
    "    probs = torch.sigmoid(mask_logits).cpu().numpy()\n",
    "    pred = (probs >= threshold).astype(int)\n",
    "    true = mask_y.cpu().numpy()\n",
    "    \n",
    "    metrics = compute_metrics(true, pred, y_probs=probs)\n",
    "    \n",
    "    return loss, metrics, true, pred, probs\n",
    "\n",
    "print(\"‚úÖ Training functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19252c2f",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Load Data\n",
    "Thay ƒë·ªïi path n·∫øu c·∫ßn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (adjust paths as needed)\n",
    "print(\"üìÇ Loading data from dataset-processed...\")\n",
    "\n",
    "X = np.load('/kaggle/input/cicids-cleaned/dataset-processed/X.npy')\n",
    "y = np.load('/kaggle/input/cicids-cleaned/dataset-processed/y.npy')\n",
    "idx_train = np.load('/kaggle/input/cicids-cleaned/dataset-processed/idx_train.npy')\n",
    "idx_val = np.load('/kaggle/input/cicids-cleaned/dataset-processed/idx_val.npy')\n",
    "idx_test = np.load('/kaggle/input/cicids-cleaned/dataset-processed/idx_test.npy')\n",
    "\n",
    "print(f\"‚úÖ Data loaded:\")\n",
    "print(f\"   X shape: {X.shape}\")\n",
    "print(f\"   y shape: {y.shape}\")\n",
    "print(f\"   Train: {len(idx_train):,} samples\")\n",
    "print(f\"   Val:   {len(idx_val):,} samples\")\n",
    "print(f\"   Test:  {len(idx_test):,} samples\")\n",
    "print(f\"   Attack ratio: {(y==1).sum()/len(y):.2%}\")\n",
    "\n",
    "# üî• OPTIONAL: Limit dataset size for faster training on Kaggle\n",
    "MAX_SAMPLES = None  # Set to None to use full dataset, or 2_000_000 for 2M samples\n",
    "\n",
    "if MAX_SAMPLES is not None and len(X) > MAX_SAMPLES:\n",
    "    print(f\"\\n‚ö†Ô∏è  Dataset has {len(X):,} samples, limiting to {MAX_SAMPLES:,}...\")\n",
    "    \n",
    "    # Strategy: Sample from each split proportionally to maintain distribution\n",
    "    train_limit = int(MAX_SAMPLES * len(idx_train) / len(X))\n",
    "    val_limit = int(MAX_SAMPLES * len(idx_val) / len(X))\n",
    "    test_limit = MAX_SAMPLES - train_limit - val_limit\n",
    "    \n",
    "    # Sample indices\n",
    "    np.random.seed(42)\n",
    "    idx_train_sampled = np.random.choice(idx_train, size=min(train_limit, len(idx_train)), replace=False)\n",
    "    idx_val_sampled = np.random.choice(idx_val, size=min(val_limit, len(idx_val)), replace=False)\n",
    "    idx_test_sampled = np.random.choice(idx_test, size=min(test_limit, len(idx_test)), replace=False)\n",
    "    \n",
    "    # Combine all selected indices\n",
    "    all_selected_idx = np.concatenate([idx_train_sampled, idx_val_sampled, idx_test_sampled])\n",
    "    all_selected_idx.sort()\n",
    "    \n",
    "    # Filter data\n",
    "    X = X[all_selected_idx]\n",
    "    y = y[all_selected_idx]\n",
    "    \n",
    "    # Remap indices to new positions\n",
    "    idx_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(all_selected_idx)}\n",
    "    idx_train = np.array([idx_mapping[idx] for idx in idx_train_sampled])\n",
    "    idx_val = np.array([idx_mapping[idx] for idx in idx_val_sampled])\n",
    "    idx_test = np.array([idx_mapping[idx] for idx in idx_test_sampled])\n",
    "    \n",
    "    print(f\"‚úÖ Data limited:\")\n",
    "    print(f\"   X shape: {X.shape}\")\n",
    "    print(f\"   y shape: {y.shape}\")\n",
    "    print(f\"   Train: {len(idx_train):,} samples\")\n",
    "    print(f\"   Val:   {len(idx_val):,} samples\")\n",
    "    print(f\"   Test:  {len(idx_test):,} samples\")\n",
    "    print(f\"   Attack ratio: {(y==1).sum()/len(y):.2%}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Using full dataset: {len(X):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b592c",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Build KNN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî® Building KNN graph on FULL dataset...\")\n",
    "edge_index = build_knn_graph(X, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e2209",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Prepare Data & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.from_numpy(X).float()\n",
    "y_tensor = torch.from_numpy(y).long()\n",
    "\n",
    "# Ensure edge_index is contiguous\n",
    "edge_index = edge_index.contiguous()\n",
    "\n",
    "# Create masks\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "train_mask[idx_train] = True\n",
    "\n",
    "val_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "val_mask[idx_val] = True\n",
    "\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask[idx_test] = True\n",
    "\n",
    "print(f\"‚úÖ Tensors created\")\n",
    "print(f\"   x_tensor: {x_tensor.shape}\")\n",
    "print(f\"   y_tensor: {y_tensor.shape}\")\n",
    "print(f\"   edge_index: {edge_index.shape}\")\n",
    "\n",
    "# Configuration - matching flow_gnn/config.yaml\n",
    "config = {\n",
    "    'model': {\n",
    "        'hidden_dim': 128,\n",
    "        'num_classes': 2,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': 50,\n",
    "        'batch_size': 512,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 0.0001,\n",
    "        'patience': 10,\n",
    "        'min_delta': 0.001\n",
    "    },\n",
    "    'output_dir': 'output'\n",
    "}\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Model: {config['model']}\")\n",
    "print(f\"   Training: {config['training']}\")\n",
    "\n",
    "# Get device\n",
    "device = get_device(\"auto\")\n",
    "print(f\"\\nüñ•Ô∏è  Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3422b0",
   "metadata": {},
   "source": [
    "## üîü Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "metrics = train_flow_gnn(\n",
    "    x_tensor, \n",
    "    y_tensor, \n",
    "    edge_index,\n",
    "    train_mask, \n",
    "    val_mask, \n",
    "    test_mask,\n",
    "    config, \n",
    "    device\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ab3c2",
   "metadata": {},
   "source": [
    "## üéâ Done!\n",
    "Model ƒë√£ ƒë∆∞·ª£c train xong. C√°c metrics ƒë√£ ƒë∆∞·ª£c in ra ·ªü tr√™n.\n",
    "\n",
    "### Metrics bao g·ªìm:\n",
    "- **Accuracy**: ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ\n",
    "- **Precision**: ƒê·ªô ch√≠nh x√°c khi d·ª± ƒëo√°n attack\n",
    "- **Recall / Detection Rate**: T·ª∑ l·ªá ph√°t hi·ªán attack\n",
    "- **F1 Score**: ƒêi·ªÉm c√¢n b·∫±ng gi·ªØa precision v√† recall\n",
    "- **FAR (False Alarm Rate)**: T·ª∑ l·ªá c·∫£nh b√°o nh·∫ßm"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
