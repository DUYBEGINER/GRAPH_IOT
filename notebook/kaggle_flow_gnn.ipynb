{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de54a76",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-geometric faiss-cpu scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f16147",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bff225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KAGGLE PATH CONFIGURATION - UPDATE THIS!\n",
    "# ============================================================================\n",
    "# Example: If you added dataset named 'graph-iot-dataset', use:\n",
    "# DATA_DIR = \"/kaggle/input/graph-iot-dataset/dataset-processed/flow_gnn\"\n",
    "DATA_DIR = \"/kaggle/input/YOUR-DATASET-NAME/dataset-processed/flow_gnn\"\n",
    "OUTPUT_DIR = \"/kaggle/working/output/flow_gnn\"\n",
    "\n",
    "# ============================================================================\n",
    "# PROJECT SETTINGS\n",
    "# ============================================================================\n",
    "PROJECT_NAME = \"Flow-GNN\"\n",
    "SEED = 42\n",
    "DEVICE = \"auto\"  # auto, cuda, mps, cpu\n",
    "\n",
    "# ============================================================================\n",
    "# DATA SETTINGS\n",
    "# ============================================================================\n",
    "MAX_SAMPLES = 2_000_000\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL SETTINGS\n",
    "# ============================================================================\n",
    "HIDDEN_DIM = 128\n",
    "NUM_CLASSES = 2\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# ============================================================================\n",
    "# GRAPH SETTINGS\n",
    "# ============================================================================\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING SETTINGS\n",
    "# ============================================================================\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706cc82c",
   "metadata": {},
   "source": [
    "## 3. Imports and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import faiss\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, classification_report,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from typing import Dict, Optional\n",
    "\n",
    "print(\"âœ… Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def get_device(device_str: str = \"auto\") -> torch.device:\n",
    "    \"\"\"Get PyTorch device.\"\"\"\n",
    "    if device_str == \"auto\":\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "            print(\"Using Apple Metal (MPS)\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"Using CPU\")\n",
    "    else:\n",
    "        device = torch.device(device_str)\n",
    "        print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                    y_probs: Optional[np.ndarray] = None) -> Dict[str, float]:\n",
    "    \"\"\"Compute comprehensive metrics.\"\"\"\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    metrics[\"true_positive\"] = int(tp)\n",
    "    metrics[\"true_negative\"] = int(tn)\n",
    "    metrics[\"false_positive\"] = int(fp)\n",
    "    metrics[\"false_negative\"] = int(fn)\n",
    "    metrics[\"far\"] = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    metrics[\"detection_rate\"] = metrics[\"recall\"]\n",
    "    \n",
    "    if y_probs is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "        metrics[\"auc\"] = auc(fpr, tpr)\n",
    "        metrics[\"average_precision\"] = average_precision_score(y_true, y_probs)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping callback to prevent overfitting.\"\"\"\n",
    "    def __init__(self, patience: int = 10, min_delta: float = 1e-4):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "    \n",
    "    def __call__(self, score: float) -> bool:\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return False\n",
    "        if score > self.best_score + self.min_delta:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "print(\"âœ… Utilities defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75c6a3",
   "metadata": {},
   "source": [
    "## 4. Build KNN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn_graph(X_scaled: np.ndarray, k: int = K_NEIGHBORS) -> torch.Tensor:\n",
    "    \"\"\"Build KNN graph with FAISS.\"\"\"\n",
    "    print(f\"\\nðŸ”¨ Building KNN graph (k={k})...\")\n",
    "    \n",
    "    X = np.ascontiguousarray(X_scaled, dtype=np.float32)\n",
    "    n_samples, n_features = X.shape\n",
    "    print(f\"   Data shape: {n_samples:,} samples Ã— {n_features} features\")\n",
    "    \n",
    "    with tqdm(total=3, desc=\"ðŸ“ Graph construction\", ncols=100) as main_pbar:\n",
    "        faiss.normalize_L2(X)\n",
    "        main_pbar.update(1)\n",
    "        main_pbar.set_postfix_str(\"Normalized vectors\")\n",
    "        \n",
    "        index = faiss.IndexFlatIP(n_features)\n",
    "        index.add(X)\n",
    "        main_pbar.update(1)\n",
    "        main_pbar.set_postfix_str(\"Built FAISS index\")\n",
    "        \n",
    "        batch_size = 10000\n",
    "        all_indices = []\n",
    "        \n",
    "        for i in tqdm(range(0, n_samples, batch_size),\n",
    "                      desc=\"   ðŸ” KNN search\", unit=\"batch\", ncols=100, leave=False):\n",
    "            end_idx = min(i + batch_size, n_samples)\n",
    "            _, indices = index.search(X[i:end_idx], k + 1)\n",
    "            all_indices.append(indices)\n",
    "        \n",
    "        indices = np.vstack(all_indices)\n",
    "        main_pbar.update(1)\n",
    "        main_pbar.set_postfix_str(\"KNN search complete\")\n",
    "    \n",
    "    indices = indices[:, 1:]\n",
    "    \n",
    "    print(\"   ðŸ”— Building edge list...\")\n",
    "    row = np.repeat(np.arange(n_samples), k)\n",
    "    col = indices.flatten()\n",
    "    \n",
    "    edges = np.vstack([\n",
    "        np.concatenate([row, col]),\n",
    "        np.concatenate([col, row])\n",
    "    ])\n",
    "    \n",
    "    edges = np.unique(edges, axis=1)\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "    \n",
    "    num_edges = edge_index.shape[1]\n",
    "    avg_degree = num_edges / n_samples\n",
    "    \n",
    "    print(f\"âœ… KNN graph built: {num_edges:,} edges, avg degree: {avg_degree:.2f}\")\n",
    "    return edge_index\n",
    "\n",
    "print(\"âœ… KNN graph function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c214c",
   "metadata": {},
   "source": [
    "## 5. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowGraphSAGE(nn.Module):\n",
    "    \"\"\"GraphSAGE model for flow classification (node classification).\"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim: int, hidden_dim: int = 128, num_classes: int = 2,\n",
    "                 num_layers: int = 2, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_dim, hidden_dim))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        if num_layers > 1:\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        self.bns = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        print(f\"   FlowGraphSAGE: {in_dim}â†’{hidden_dim}x{num_layers}â†’1 (binary)\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass. Returns logits (no sigmoid).\"\"\"\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "print(\"âœ… Model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219a1e0",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNodeSampler:\n",
    "    \"\"\"Simple random node sampler for mini-batch training.\"\"\"\n",
    "    def __init__(self, mask: torch.Tensor, batch_size: int, shuffle: bool = True):\n",
    "        self.node_indices = mask.nonzero(as_tuple=True)[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = self.node_indices.clone()\n",
    "        if self.shuffle:\n",
    "            perm = torch.randperm(len(indices))\n",
    "            indices = indices[perm]\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            yield indices[i:i + self.batch_size]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.node_indices) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "def evaluate(model, data, mask, criterion, device, threshold=0.5):\n",
    "    \"\"\"Evaluate model on given mask.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        mask_logits = logits[mask]\n",
    "        mask_y = data.y[mask]\n",
    "        loss = criterion(mask_logits, mask_y.float()).item()\n",
    "    \n",
    "    probs = torch.sigmoid(mask_logits).cpu().numpy()\n",
    "    pred = (probs >= threshold).astype(int)\n",
    "    true = mask_y.cpu().numpy()\n",
    "    metrics = compute_metrics(true, pred, y_probs=probs)\n",
    "    return loss, metrics\n",
    "\n",
    "def evaluate_with_predictions(model, data, mask, criterion, threshold, device):\n",
    "    \"\"\"Evaluate and return predictions.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        mask_logits = logits[mask]\n",
    "        mask_y = data.y[mask]\n",
    "        loss = criterion(mask_logits, mask_y.float()).item()\n",
    "    \n",
    "    probs = torch.sigmoid(mask_logits).cpu().numpy()\n",
    "    pred = (probs >= threshold).astype(int)\n",
    "    true = mask_y.cpu().numpy()\n",
    "    metrics = compute_metrics(true, pred, y_probs=probs)\n",
    "    return loss, metrics, true, pred, probs\n",
    "\n",
    "def tune_threshold(model, data, mask, device):\n",
    "    \"\"\"Find optimal threshold to maximize F1 score.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        val_logits = logits[mask]\n",
    "        val_targets = data.y[mask]\n",
    "    \n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "    y_val_np = val_targets.cpu().numpy()\n",
    "    \n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    for t in tqdm(thresholds, desc=\"   Searching threshold\", ncols=100, leave=False):\n",
    "        y_pred = (val_probs >= t).astype(int)\n",
    "        f1 = f1_score(y_val_np, y_pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "    return best_t\n",
    "\n",
    "print(\"âœ… Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39078b5",
   "metadata": {},
   "source": [
    "## 7. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "device = get_device(DEVICE)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ”· FLOW-BASED GNN PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "data_dir = Path(DATA_DIR)\n",
    "print(f\"\\nðŸ“‚ [1/4] Loading preprocessed data...\")\n",
    "print(f\"   Data directory: {data_dir}\")\n",
    "\n",
    "X = np.load(data_dir / \"X.npy\")\n",
    "y = np.load(data_dir / \"y.npy\")\n",
    "idx_train = np.load(data_dir / \"idx_train.npy\")\n",
    "idx_val = np.load(data_dir / \"idx_val.npy\")\n",
    "idx_test = np.load(data_dir / \"idx_test.npy\")\n",
    "\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(f\"   Features: {x_tensor.shape}\")\n",
    "print(f\"   Train: {len(idx_train):,} | Val: {len(idx_val):,} | Test: {len(idx_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd9a34",
   "metadata": {},
   "source": [
    "## 8. Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e66ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”¨ [2/4] Building KNN graph...\")\n",
    "edge_index = build_knn_graph(X, k=K_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a3eed",
   "metadata": {},
   "source": [
    "## 9. Create Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ab6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¯ [3/4] Creating train/val/test masks...\")\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "val_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "train_mask[idx_train] = True\n",
    "val_mask[idx_val] = True\n",
    "test_mask[idx_test] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f4a0d",
   "metadata": {},
   "source": [
    "## 10. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ [4/4] Training model...\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸš€ TRAINING FLOW-BASED GNN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create PyG Data\n",
    "data = Data(\n",
    "    x=x_tensor,\n",
    "    edge_index=edge_index,\n",
    "    y=y_tensor,\n",
    "    train_mask=train_mask,\n",
    "    val_mask=val_mask,\n",
    "    test_mask=test_mask\n",
    ").to(device)\n",
    "\n",
    "# Calculate pos_weight\n",
    "y_train = y_tensor[train_mask]\n",
    "pos = (y_train == 1).sum().item()\n",
    "neg = (y_train == 0).sum().item()\n",
    "pos_weight = neg / pos if pos > 0 else 1.0\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Training samples:   {train_mask.sum().item():,}\")\n",
    "print(f\"   Validation samples: {val_mask.sum().item():,}\")\n",
    "print(f\"   Test samples:       {test_mask.sum().item():,}\")\n",
    "print(f\"   Class distribution: Benign={neg:,} ({neg/(neg+pos)*100:.1f}%), Attack={pos:,} ({pos/(neg+pos)*100:.1f}%)\")\n",
    "print(f\"   Positive weight:    {pos_weight:.4f}\")\n",
    "\n",
    "# Model\n",
    "print(f\"\\nðŸ—ï¸  Model Configuration:\")\n",
    "print(f\"   Hidden dim:  {HIDDEN_DIM}\")\n",
    "print(f\"   Num layers:  {NUM_LAYERS}\")\n",
    "print(f\"   Dropout:     {DROPOUT}\")\n",
    "\n",
    "model = FlowGraphSAGE(\n",
    "    in_dim=x_tensor.shape[1],\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"   Total params: {total_params:,}\")\n",
    "print(f\"   Device:       {device}\")\n",
    "\n",
    "# Optimizer & Loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor([pos_weight], device=device)\n",
    ")\n",
    "\n",
    "print(f\"\\nâš™ï¸  Training Configuration:\")\n",
    "print(f\"   Epochs:         {EPOCHS}\")\n",
    "print(f\"   Batch size:     {BATCH_SIZE}\")\n",
    "print(f\"   Learning rate:  {LEARNING_RATE}\")\n",
    "print(f\"   Weight decay:   {WEIGHT_DECAY}\")\n",
    "print(f\"   Early stopping: {PATIENCE} epochs\")\n",
    "\n",
    "# Training setup\n",
    "train_sampler = RandomNodeSampler(train_mask, batch_size=BATCH_SIZE, shuffle=True)\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, min_delta=MIN_DELTA)\n",
    "\n",
    "best_f1 = 0.0\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_f1': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ”¥ Starting Training...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "epoch_pbar = tqdm(range(1, EPOCHS + 1), desc=\"Training\", unit=\"epoch\", ncols=100)\n",
    "\n",
    "for epoch in epoch_pbar:\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_nodes in train_sampler:\n",
    "        batch_nodes = batch_nodes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(data.x, data.edge_index)\n",
    "        loss = criterion(logits[batch_nodes], data.y[batch_nodes].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    train_loss = total_loss / num_batches\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics = evaluate(model, data, val_mask, criterion, device)\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "    \n",
    "    # Update progress bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'loss': f\"{train_loss:.4f}\",\n",
    "        'val_f1': f\"{val_metrics['f1']:.4f}\",\n",
    "        'val_acc': f\"{val_metrics['accuracy']:.4f}\"\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['f1'] > best_f1:\n",
    "        best_f1 = val_metrics['f1']\n",
    "        save_path = Path(OUTPUT_DIR) / 'best_model.pt'\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': val_metrics\n",
    "        }, save_path)\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping(val_metrics['f1']):\n",
    "        print(f\"\\nâš ï¸  Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nâœ… Training completed! Best validation F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e60534",
   "metadata": {},
   "source": [
    "## 11. Tune Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e28a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸŽ¯ TUNING DECISION THRESHOLD\")\n",
    "print(\"=\" * 70)\n",
    "best_threshold = tune_threshold(model, data, val_mask, device)\n",
    "print(f\"âœ… Optimal threshold: {best_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e52c6b",
   "metadata": {},
   "source": [
    "## 12. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a811d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ§ª FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "test_loss, test_metrics, y_true, y_pred, y_probs = evaluate_with_predictions(\n",
    "    model, data, test_mask, criterion, best_threshold, device\n",
    ")\n",
    "inference_time = time.time() - start_time\n",
    "latency_per_sample = inference_time / len(y_true)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Test Results:\")\n",
    "print(f\"   Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall:    {test_metrics['recall']:.4f}\")\n",
    "print(f\"   F1 Score:  {test_metrics['f1']:.4f}\")\n",
    "print(f\"   AUC:       {test_metrics.get('auc', 0):.4f}\")\n",
    "print(f\"   FAR:       {test_metrics['far']:.4f}\")\n",
    "print(f\"\\nâ±ï¸  Inference Performance:\")\n",
    "print(f\"   Total time:   {inference_time:.2f}s\")\n",
    "print(f\"   Latency:      {latency_per_sample*1000:.4f} ms/sample\")\n",
    "print(f\"   Throughput:   {len(y_true)/inference_time:.2f} samples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaff7be",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26860d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(OUTPUT_DIR)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save metrics as JSON\n",
    "test_metrics['latency_seconds'] = latency_per_sample\n",
    "test_metrics['latency_ms'] = latency_per_sample * 1000\n",
    "with open(output_path / 'metrics.json', 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=2)\n",
    "\n",
    "# Save classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['Benign', 'Attack'], digits=4)\n",
    "with open(output_path / 'classification_report.txt', 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"   FLOW-GNN CLASSIFICATION REPORT\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Results saved to {output_path}/\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ¨ ALL DONE!\")\n",
    "print(\"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7cfc9",
   "metadata": {},
   "source": [
    "## 14. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Benign', 'Attack'],\n",
    "            yticklabels=['Benign', 'Attack'], ax=ax)\n",
    "ax.set_title('Confusion Matrix - Flow GNN', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'confusion_matrix.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, color='#2196F3', lw=2.5, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve - Flow GNN', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'roc_curve.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Training History\n",
    "if len(history['train_loss']) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training & Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(epochs, history['val_f1'], 'g-', label='Val F1', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('F1 Score')\n",
    "    axes[1].set_title('Validation F1 Score')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[2].plot(epochs, history['val_accuracy'], 'm-', label='Val Accuracy', linewidth=2)\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Accuracy')\n",
    "    axes[2].set_title('Validation Accuracy')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path / 'training_history.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Visualizations complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
